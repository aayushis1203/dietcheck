{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aayushis1203/dietcheck/blob/main/00_DietCheck_data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc9de5b3",
      "metadata": {
        "id": "dc9de5b3"
      },
      "source": [
        "\n",
        "# 00 ‚Äì Data Collection & Preparation for DietCheck\n",
        "\n",
        "**Course:** CS6120 ‚Äì Natural Language Processing  \n",
        "**Project:** DietCheck ‚Äì NLP System for Dietary Claim Verification  \n",
        "**Notebook:** `00` ‚Äì Core data preparation, numeric labels for Task 1, and claim subsets for Task 2.\n",
        "\n",
        "This notebook does the following:\n",
        "\n",
        "1. Loads the **core product table** (`products.csv`) for DietCheck.\n",
        "2. Computes **per-serving nutrition features** and **Task 1 dietary labels**:\n",
        "   - `keto_compliant`, `high_protein`, `low_sodium`, `low_fat`  \n",
        "     (using the FDA-style thresholds in the research plan).\n",
        "3. Creates **train/validation/test splits** with label-combination awareness.\n",
        "4. Extracts a **small, high-precision set of claim-like strings** from `products.csv`\n",
        "   for **Task 2 manual annotation** ‚Üí `candidate_claims_task2.csv`.\n",
        "5. Builds a **claim-rich subset from OpenFoodFacts via HuggingFace** using\n",
        "   `labels_tags` ‚Üí `openfoodfacts_claims_subset.csv` for additional Task 2 data.\n",
        "\n",
        "You should run this notebook top-to-bottom in a Colab or local environment with internet access\n",
        "(for the HuggingFace step).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Cell 1: Imports, paths, and logging\n",
        "# ======================================================================\n",
        "\n",
        "import os\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import logging\n",
        "\n",
        "# Configure basic logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "    datefmt=\"%H:%M:%S\",\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# Data directory\n",
        "DATA_DIR = Path(\"data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"DATA_DIR set to: {DATA_DIR.resolve()}\")\n",
        "print(f\"Random seed set to: {RANDOM_SEED}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvQ8Cs2Rp3_L",
        "outputId": "46ba8dc9-f8da-43e5-e5dc-81260ea5ba92"
      },
      "id": "xvQ8Cs2Rp3_L",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_DIR set to: /content/data\n",
            "Random seed set to: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Cell 2: Load products.csv\n",
        "# ======================================================================\n",
        "\n",
        "products_path = DATA_DIR / \"products.csv\"\n",
        "\n",
        "if not products_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Expected {products_path} to exist.\\n\"\n",
        "        \"Please copy your DietCheck products table to data/products.csv and re-run.\"\n",
        "    )\n",
        "\n",
        "df = pd.read_csv(products_path)\n",
        "print(f\"‚úì Loaded products.csv with shape: {df.shape}\")\n",
        "print(f\"‚úì Columns: {list(df.columns)}\")\n",
        "print(f\"‚úì Product count: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBXVAponp7V_",
        "outputId": "6a63945c-34b6-4d25-bc68-6972942f921b"
      },
      "id": "sBXVAponp7V_",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Loaded products.csv with shape: (279, 29)\n",
            "‚úì Columns: ['product_id', 'name', 'brand', 'category', 'ingredients', 'serving_size_g', 'energy_100g', 'fat_100g', 'saturated_fat_100g', 'carbs_100g', 'fiber_100g', 'sugars_100g', 'protein_100g', 'sodium_100g', 'net_carbs_100g', 'energy_per_serving', 'fat_per_serving', 'saturated_fat_per_serving', 'carbs_per_serving', 'fiber_per_serving', 'sugars_per_serving', 'protein_per_serving', 'sodium_per_serving', 'net_carbs_per_serving', 'keto_compliant', 'high_protein', 'low_sodium', 'low_fat', 'label_combination']\n",
            "‚úì Product count: 279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Cell 3: Compute per-serving nutrition and Task 1 labels\n",
        "# ======================================================================\n",
        "\n",
        "print(\"\\n‚û§ Computing per-serving nutrition and Task 1 dietary labels...\\n\")\n",
        "\n",
        "# Check if per-serving columns already exist\n",
        "serving_cols = [\"energy_per_serving\", \"fat_per_serving\", \"protein_per_serving\",\n",
        "                \"sodium_per_serving\", \"carbs_per_serving\", \"fiber_per_serving\",\n",
        "                \"saturated_fat_per_serving\", \"sugars_per_serving\", \"net_carbs_per_serving\"]\n",
        "\n",
        "if all(col in df.columns for col in serving_cols):\n",
        "    print(\"‚úì Per-serving columns already exist, skipping computation\")\n",
        "else:\n",
        "    print(\"Computing per-serving values from 100g data...\")\n",
        "\n",
        "    # Compute per-serving values\n",
        "    df[\"energy_per_serving\"] = df[\"energy_100g\"] * df[\"serving_size_g\"] / 100.0\n",
        "    df[\"fat_per_serving\"] = df[\"fat_100g\"] * df[\"serving_size_g\"] / 100.0\n",
        "    df[\"saturated_fat_per_serving\"] = df[\"saturated_fat_100g\"] * df[\"serving_size_g\"] / 100.0\n",
        "    df[\"carbs_per_serving\"] = df[\"carbs_100g\"] * df[\"serving_size_g\"] / 100.0\n",
        "    df[\"fiber_per_serving\"] = df[\"fiber_100g\"] * df[\"serving_size_g\"] / 100.0\n",
        "    df[\"sugars_per_serving\"] = df[\"sugars_100g\"] * df[\"serving_size_g\"] / 100.0\n",
        "    df[\"protein_per_serving\"] = df[\"protein_100g\"] * df[\"serving_size_g\"] / 100.0\n",
        "    df[\"sodium_per_serving\"] = df[\"sodium_100g\"] * df[\"serving_size_g\"] / 100.0\n",
        "\n",
        "    # Net carbs\n",
        "    df[\"net_carbs_per_serving\"] = (\n",
        "        df[\"carbs_per_serving\"] - df[\"fiber_per_serving\"]\n",
        "    ).fillna(df[\"carbs_per_serving\"])\n",
        "\n",
        "    print(\"‚úì Per-serving values computed\")\n",
        "\n",
        "# Check if Task 1 labels already exist\n",
        "label_cols = [\"keto_compliant\", \"high_protein\", \"low_sodium\", \"low_fat\"]\n",
        "\n",
        "if all(col in df.columns for col in label_cols):\n",
        "    print(\"‚úì Task 1 labels already exist, skipping computation\")\n",
        "else:\n",
        "    print(\"Computing Task 1 dietary classification labels...\")\n",
        "\n",
        "    # FDA thresholds (adjusted for keto as per research plan)\n",
        "    KETO_NET_CARBS_THRESHOLD = 40.0  # Adjusted from 5g as documented\n",
        "    HIGH_PROTEIN_THRESHOLD = 10.0     # grams (20% DV)\n",
        "    LOW_SODIUM_THRESHOLD = 140.0      # mg\n",
        "    LOW_FAT_THRESHOLD = 3.0           # grams\n",
        "\n",
        "    df[\"keto_compliant\"] = (df[\"net_carbs_per_serving\"] <= KETO_NET_CARBS_THRESHOLD).fillna(False)\n",
        "    df[\"high_protein\"] = (df[\"protein_per_serving\"] >= HIGH_PROTEIN_THRESHOLD).fillna(False)\n",
        "    df[\"low_sodium\"] = (df[\"sodium_per_serving\"] <= LOW_SODIUM_THRESHOLD).fillna(False)\n",
        "    df[\"low_fat\"] = (df[\"fat_per_serving\"] <= LOW_FAT_THRESHOLD).fillna(False)\n",
        "\n",
        "    print(\"‚úì Task 1 labels computed\")\n",
        "\n",
        "# Create label combination for stratification\n",
        "df[\"label_combination\"] = (\n",
        "    df[\"keto_compliant\"].astype(str) + \"_\" +\n",
        "    df[\"high_protein\"].astype(str) + \"_\" +\n",
        "    df[\"low_sodium\"].astype(str) + \"_\" +\n",
        "    df[\"low_fat\"].astype(str)\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úì Total products: {len(df)}\")\n",
        "print(f\"‚úì Unique label combinations: {df['label_combination'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44U5IHpDp9Ah",
        "outputId": "2c0242e1-e6ce-481c-d54c-15211b6d644b"
      },
      "id": "44U5IHpDp9Ah",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚û§ Computing per-serving nutrition and Task 1 dietary labels...\n",
            "\n",
            "‚úì Per-serving columns already exist, skipping computation\n",
            "‚úì Task 1 labels already exist, skipping computation\n",
            "\n",
            "‚úì Total products: 279\n",
            "‚úì Unique label combinations: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Cell 4: Data quality and stratification report\n",
        "# ======================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA QUALITY REPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Overall counts\n",
        "print(f\"\\nüìä OVERALL STATISTICS\")\n",
        "print(f\"  ‚Ä¢ Total products: {len(df)}\")\n",
        "print(f\"  ‚Ä¢ Products with ingredients: {df['ingredients'].notna().sum()}\")\n",
        "print(f\"  ‚Ä¢ Products with complete nutrition: {df[['fat_per_serving', 'protein_per_serving', 'sodium_per_serving', 'carbs_per_serving']].notna().all(axis=1).sum()}\")\n",
        "\n",
        "# Task 1 label distribution\n",
        "print(f\"\\nüè∑Ô∏è  TASK 1 LABEL DISTRIBUTION\")\n",
        "for label in [\"keto_compliant\", \"high_protein\", \"low_sodium\", \"low_fat\"]:\n",
        "    count = df[label].sum()\n",
        "    pct = (count / len(df) * 100) if len(df) > 0 else 0\n",
        "    print(f\"  ‚Ä¢ {label}: {count} ({pct:.1f}%)\")\n",
        "\n",
        "# Category distribution (if exists)\n",
        "if \"category\" in df.columns:\n",
        "    print(f\"\\nüì¶ CATEGORY DISTRIBUTION (Top 8)\")\n",
        "    print(df[\"category\"].value_counts().head(8))\n",
        "\n",
        "# Label combinations\n",
        "print(f\"\\nüîÄ LABEL COMBINATIONS (Top 10)\")\n",
        "print(df[\"label_combination\"].value_counts().head(10))\n",
        "\n",
        "# Nutrient completeness\n",
        "print(f\"\\nüß™ NUTRIENT DATA COMPLETENESS\")\n",
        "nutrient_cols = [\"fat_per_serving\", \"protein_per_serving\", \"sodium_per_serving\",\n",
        "                 \"carbs_per_serving\", \"fiber_per_serving\", \"sugars_per_serving\"]\n",
        "for col in nutrient_cols:\n",
        "    if col in df.columns:\n",
        "        count = df[col].notna().sum()\n",
        "        pct = (count / len(df) * 100) if len(df) > 0 else 0\n",
        "        print(f\"  ‚Ä¢ {col}: {count}/{len(df)} ({pct:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxVnLaDwp_MW",
        "outputId": "8b1729ae-2941-4c53-c416-c52e1c235b07"
      },
      "id": "pxVnLaDwp_MW",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATA QUALITY REPORT\n",
            "======================================================================\n",
            "\n",
            "üìä OVERALL STATISTICS\n",
            "  ‚Ä¢ Total products: 279\n",
            "  ‚Ä¢ Products with ingredients: 279\n",
            "  ‚Ä¢ Products with complete nutrition: 279\n",
            "\n",
            "üè∑Ô∏è  TASK 1 LABEL DISTRIBUTION\n",
            "  ‚Ä¢ keto_compliant: 90 (32.3%)\n",
            "  ‚Ä¢ high_protein: 105 (37.6%)\n",
            "  ‚Ä¢ low_sodium: 124 (44.4%)\n",
            "  ‚Ä¢ low_fat: 103 (36.9%)\n",
            "\n",
            "üì¶ CATEGORY DISTRIBUTION (Top 8)\n",
            "category\n",
            "en:plant-based-foods-and-beverages         130\n",
            "en:dairies                                  47\n",
            "en:beverages-and-beverages-preparations     29\n",
            "en:condiments                               23\n",
            "en:snacks                                   18\n",
            "en:seafood                                  10\n",
            "en:meals                                     6\n",
            "en:meats-and-their-products                  5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üîÄ LABEL COMBINATIONS (Top 10)\n",
            "label_combination\n",
            "0_1_0_0    68\n",
            "1_0_1_1    40\n",
            "0_0_0_0    30\n",
            "0_0_1_0    29\n",
            "0_0_1_1    21\n",
            "1_0_0_0    15\n",
            "0_0_0_1    14\n",
            "1_0_1_0    13\n",
            "0_1_1_0    12\n",
            "1_0_0_1    12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üß™ NUTRIENT DATA COMPLETENESS\n",
            "  ‚Ä¢ fat_per_serving: 279/279 (100.0%)\n",
            "  ‚Ä¢ protein_per_serving: 279/279 (100.0%)\n",
            "  ‚Ä¢ sodium_per_serving: 279/279 (100.0%)\n",
            "  ‚Ä¢ carbs_per_serving: 279/279 (100.0%)\n",
            "  ‚Ä¢ fiber_per_serving: 279/279 (100.0%)\n",
            "  ‚Ä¢ sugars_per_serving: 279/279 (100.0%)\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Cell 5: Create train/validation/test splits (robust to rare combos)\n",
        "# ======================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"\\n‚û§ Creating train/validation/test splits...\\n\")\n",
        "\n",
        "if \"label_combination\" not in df.columns:\n",
        "    raise KeyError(\"Expected 'label_combination' column to exist before creating splits.\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1) Handle rare label combinations (appearing only once in full df)\n",
        "# ------------------------------------------------------------------\n",
        "combo_counts = df[\"label_combination\"].value_counts()\n",
        "\n",
        "# Combinations we can safely stratify on (at least 2 samples in full df)\n",
        "combos_ge2 = combo_counts[combo_counts >= 2].index\n",
        "\n",
        "df_strat = df[df[\"label_combination\"].isin(combos_ge2)].copy()\n",
        "df_rare = df[~df[\"label_combination\"].isin(combos_ge2)].copy()\n",
        "\n",
        "print(f\"  ‚Ä¢ Total products: {len(df)}\")\n",
        "print(f\"  ‚Ä¢ Stratifiable products (combo count ‚â• 2): {len(df_strat)}\")\n",
        "print(f\"  ‚Ä¢ Rare combos (count = 1): {len(df_rare)}\")\n",
        "\n",
        "# If we basically have no stratifiable data, fall back to simple split\n",
        "if len(df_strat) < 2:\n",
        "    print(\"\\n‚ö†Ô∏è  Too few stratifiable products. Falling back to NON-stratified split.\\n\")\n",
        "\n",
        "    df_train, df_temp = train_test_split(\n",
        "        df,\n",
        "        test_size=0.3,\n",
        "        random_state=RANDOM_SEED,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    df_val, df_test = train_test_split(\n",
        "        df_temp,\n",
        "        test_size=0.5,\n",
        "        random_state=RANDOM_SEED,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "else:\n",
        "    # ------------------------------------------------------------------\n",
        "    # 2) First split: TRAIN vs (VAL+TEST) with stratification\n",
        "    # ------------------------------------------------------------------\n",
        "    print(\"\\n‚û§ Performing stratified split on frequent label combinations (train vs temp)...\\n\")\n",
        "\n",
        "    df_train_strat, df_temp = train_test_split(\n",
        "        df_strat,\n",
        "        test_size=0.3,\n",
        "        random_state=RANDOM_SEED,\n",
        "        stratify=df_strat[\"label_combination\"],\n",
        "    )\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 3) Second split: VAL vs TEST\n",
        "    #    Try stratification, but only if every class in df_temp has ‚â• 2\n",
        "    # ------------------------------------------------------------------\n",
        "    temp_combo_counts = df_temp[\"label_combination\"].value_counts()\n",
        "    min_temp_count = temp_combo_counts.min()\n",
        "\n",
        "    if min_temp_count < 2:\n",
        "        print(\"‚ö†Ô∏è  Cannot stratify VAL/TEST: some label_combinations in temp have only 1 sample.\")\n",
        "        print(\"   ‚Üí Using NON-stratified split for VAL/TEST.\\n\")\n",
        "\n",
        "        df_val, df_test = train_test_split(\n",
        "            df_temp,\n",
        "            test_size=0.5,\n",
        "            random_state=RANDOM_SEED,\n",
        "            shuffle=True,\n",
        "        )\n",
        "    else:\n",
        "        print(\"‚û§ Performing stratified split for VAL/TEST...\\n\")\n",
        "\n",
        "        df_val, df_test = train_test_split(\n",
        "            df_temp,\n",
        "            test_size=0.5,\n",
        "            random_state=RANDOM_SEED,\n",
        "            stratify=df_temp[\"label_combination\"],\n",
        "        )\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 4) Add all rare-combo products into the TRAIN set\n",
        "    # ------------------------------------------------------------------\n",
        "    if not df_rare.empty:\n",
        "        print(f\"‚û§ Adding {len(df_rare)} rare-combo products to the TRAIN set only\")\n",
        "        df_train = pd.concat([df_train_strat, df_rare], ignore_index=True)\n",
        "    else:\n",
        "        df_train = df_train_strat.copy()\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 5) Final sanity prints\n",
        "# ------------------------------------------------------------------\n",
        "print(f\"\\n‚úì Train set: {len(df_train)} products ({len(df_train)/len(df)*100:.1f}%)\")\n",
        "print(f\"‚úì Validation set: {len(df_val)} products ({len(df_val)/len(df)*100:.1f}%)\")\n",
        "print(f\"‚úì Test set: {len(df_test)} products ({len(df_test)/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\nLabel combination counts by split (top 10):\")\n",
        "print(\"\\n  TRAIN:\")\n",
        "print(df_train[\"label_combination\"].value_counts().head(10))\n",
        "print(\"\\n  VAL:\")\n",
        "print(df_val[\"label_combination\"].value_counts().head(10))\n",
        "print(\"\\n  TEST:\")\n",
        "print(df_test[\"label_combination\"].value_counts().head(10))\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 6) Save splits\n",
        "# ------------------------------------------------------------------\n",
        "df_train.to_csv(DATA_DIR / \"train.csv\", index=False)\n",
        "df_val.to_csv(DATA_DIR / \"val.csv\", index=False)\n",
        "df_test.to_csv(DATA_DIR / \"test.csv\", index=False)\n",
        "\n",
        "print(f\"\\n‚úì Saved splits to:\")\n",
        "print(f\"  ‚Ä¢ {DATA_DIR / 'train.csv'}\")\n",
        "print(f\"  ‚Ä¢ {DATA_DIR / 'val.csv'}\")\n",
        "print(f\"  ‚Ä¢ {DATA_DIR / 'test.csv'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyFydUUfqBBy",
        "outputId": "9f4070b8-d086-4306-982e-3f8f24217254"
      },
      "id": "FyFydUUfqBBy",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚û§ Creating train/validation/test splits...\n",
            "\n",
            "  ‚Ä¢ Total products: 279\n",
            "  ‚Ä¢ Stratifiable products (combo count ‚â• 2): 278\n",
            "  ‚Ä¢ Rare combos (count = 1): 1\n",
            "\n",
            "‚û§ Performing stratified split on frequent label combinations (train vs temp)...\n",
            "\n",
            "‚ö†Ô∏è  Cannot stratify VAL/TEST: some label_combinations in temp have only 1 sample.\n",
            "   ‚Üí Using NON-stratified split for VAL/TEST.\n",
            "\n",
            "‚û§ Adding 1 rare-combo products to the TRAIN set only\n",
            "\n",
            "‚úì Train set: 195 products (69.9%)\n",
            "‚úì Validation set: 42 products (15.1%)\n",
            "‚úì Test set: 42 products (15.1%)\n",
            "\n",
            "Label combination counts by split (top 10):\n",
            "\n",
            "  TRAIN:\n",
            "label_combination\n",
            "0_1_0_0    47\n",
            "1_0_1_1    28\n",
            "0_0_0_0    21\n",
            "0_0_1_0    20\n",
            "0_0_1_1    15\n",
            "1_0_0_0    11\n",
            "0_0_0_1    10\n",
            "1_0_1_0     9\n",
            "0_1_1_0     8\n",
            "1_0_0_1     8\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  VAL:\n",
            "label_combination\n",
            "0_1_0_0    12\n",
            "0_0_1_0     6\n",
            "0_0_0_0     5\n",
            "1_0_0_1     3\n",
            "1_0_1_1     3\n",
            "0_1_1_0     2\n",
            "1_0_1_0     2\n",
            "0_0_0_1     2\n",
            "1_0_0_0     2\n",
            "0_1_1_1     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  TEST:\n",
            "label_combination\n",
            "0_1_0_0    9\n",
            "1_0_1_1    9\n",
            "0_0_0_0    4\n",
            "0_0_1_1    4\n",
            "0_0_1_0    3\n",
            "0_1_0_1    2\n",
            "0_1_1_0    2\n",
            "1_0_1_0    2\n",
            "1_0_0_0    2\n",
            "0_0_0_1    2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "‚úì Saved splits to:\n",
            "  ‚Ä¢ data/train.csv\n",
            "  ‚Ä¢ data/val.csv\n",
            "  ‚Ä¢ data/test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Cell 6: Candidate claim extraction (HELPER for manual Task 2 annotation)\n",
        "# ======================================================================\n",
        "# NOTE: This cell ONLY extracts candidate text snippets.\n",
        "# All Task 2 labels (claim_verifiable, claim_conflict, explanations)\n",
        "# must be manually annotated by humans.\n",
        "# ======================================================================\n",
        "\n",
        "import re\n",
        "\n",
        "print(\"\\n‚û§ Extracting claim-like strings for MANUAL Task 2 annotation\\n\")\n",
        "print(\"‚ö†Ô∏è  This is a HELPER step - no automatic labels are created.\")\n",
        "print(\"‚ö†Ô∏è  All claim_verifiable and claim_conflict labels must be done manually.\\n\")\n",
        "\n",
        "source_df = df_train.copy()\n",
        "print(f\"  ‚Æï Using TRAINING split: {len(source_df)} products\")\n",
        "\n",
        "TEXT_FIELDS = [f for f in [\"name\", \"category\", \"brand\"] if f in source_df.columns]\n",
        "print(f\"  ‚Æï Scanning text fields: {TEXT_FIELDS}\\n\")\n",
        "\n",
        "CLAIM_PATTERNS = {\n",
        "    \"low_sugar\": [\n",
        "        r\"\\bno\\s+added\\s+sugar\\b\",\n",
        "        r\"\\bwithout\\s+added\\s+sugar\\b\",\n",
        "        r\"\\bsugar[-\\s]?free\\b\",\n",
        "    ],\n",
        "    \"low_fat\": [\n",
        "        r\"\\blow[-\\s]?fat\\b\",\n",
        "        r\"\\b0\\s*%\\s*fat\\b\",\n",
        "        r\"\\bfat[-\\s]?free\\b\",\n",
        "    ],\n",
        "    \"high_protein\": [\n",
        "        r\"\\b(high|rich)\\s+in\\s+protein\\b\",\n",
        "        r\"\\bprotein[-\\s]?rich\\b\",\n",
        "        r\"\\bsource\\s+of\\s+protein\\b\",\n",
        "    ],\n",
        "    \"high_fiber\": [\n",
        "        r\"\\b(high|rich)\\s+in\\s+fib(re|er)s?\\b\",\n",
        "        r\"\\bsource\\s+of\\s+fib(re|er)s?\\b\",\n",
        "    ],\n",
        "    \"low_sodium\": [\n",
        "        r\"\\blow\\s+(salt|sodium)\\b\",\n",
        "        r\"\\breduced\\s+salt\\b\",\n",
        "        r\"\\breduced\\s+sodium\\b\",\n",
        "        r\"\\bno\\s+added\\s+salt\\b\",\n",
        "    ],\n",
        "    \"gluten_free\": [\n",
        "        r\"\\bgluten[-\\s]?free\\b\",\n",
        "    ],\n",
        "    \"lactose_free\": [\n",
        "        r\"\\blactose[-\\s]?free\\b\",\n",
        "    ],\n",
        "    \"keto\": [\n",
        "        r\"\\bketo(?:genic)?\\b\",\n",
        "        r\"\\bketo[-\\s]?friendly\\b\",\n",
        "    ],\n",
        "    \"light\": [\n",
        "        r\"\\blight\\b\",\n",
        "        r\"\\blightly\\s+salted\\b\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "compiled_patterns = {\n",
        "    k: [re.compile(p, flags=re.IGNORECASE) for p in v]\n",
        "    for k, v in CLAIM_PATTERNS.items()\n",
        "}\n",
        "\n",
        "def extract_claims_from_text(pid, field_name, text, context_window=25):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return []\n",
        "    candidates = []\n",
        "    for claim_type, regex_list in compiled_patterns.items():\n",
        "        for regex in regex_list:\n",
        "            for match in regex.finditer(text):\n",
        "                start, end = match.span()\n",
        "                left = max(0, start - context_window)\n",
        "                right = min(len(text), end + context_window)\n",
        "                snippet = text[left:right].strip()\n",
        "                candidates.append(\n",
        "                    {\n",
        "                        \"product_id\": pid,\n",
        "                        \"claim_text\": snippet,\n",
        "                        \"claim_type_hint\": claim_type,\n",
        "                        \"source_field\": field_name,\n",
        "                        \"full_text\": text,\n",
        "                    }\n",
        "                )\n",
        "    return candidates\n",
        "\n",
        "all_candidates = []\n",
        "for _, row in source_df.iterrows():\n",
        "    pid = row.get(\"product_id\", None)\n",
        "    for field in TEXT_FIELDS:\n",
        "        text = row.get(field, None)\n",
        "        all_candidates.extend(\n",
        "            extract_claims_from_text(pid, field, text, context_window=25)\n",
        "        )\n",
        "\n",
        "if not all_candidates:\n",
        "    print(\"‚ö†Ô∏è  No candidate claims found with current patterns.\")\n",
        "    candidates_df = pd.DataFrame(\n",
        "        columns=[\"product_id\", \"claim_text\", \"claim_type_hint\", \"source_field\", \"full_text\"]\n",
        "    )\n",
        "else:\n",
        "    candidates_df = pd.DataFrame(all_candidates)\n",
        "    candidates_df = candidates_df.drop_duplicates(\n",
        "        subset=[\"product_id\", \"claim_text\", \"claim_type_hint\", \"source_field\"]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "print(f\"  ‚Æï Extracted {len(candidates_df)} claim-like strings\")\n",
        "\n",
        "if not candidates_df.empty:\n",
        "    print(\"\\n  ‚Æï Claim type hints (for manual review):\")\n",
        "    print(candidates_df[\"claim_type_hint\"].value_counts())\n",
        "    print(f\"\\n  ‚Æï Products with ‚â•1 claim snippet: {candidates_df['product_id'].nunique()}\")\n",
        "\n",
        "claims_path = DATA_DIR / \"candidate_claims_task2.csv\"\n",
        "candidates_df.to_csv(claims_path, index=False)\n",
        "print(f\"\\n‚úì Saved candidate claim strings to: {claims_path}\")\n",
        "print(\"  ‚Üí Use this CSV as a STARTING POINT for manual Task 2 annotation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nziftEq_qCvu",
        "outputId": "fa3c38fd-3c62-4ac6-b8a2-b90d0f9444ca"
      },
      "id": "nziftEq_qCvu",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚û§ Extracting claim-like strings for MANUAL Task 2 annotation\n",
            "\n",
            "‚ö†Ô∏è  This is a HELPER step - no automatic labels are created.\n",
            "‚ö†Ô∏è  All claim_verifiable and claim_conflict labels must be done manually.\n",
            "\n",
            "  ‚Æï Using TRAINING split: 195 products\n",
            "  ‚Æï Scanning text fields: ['name', 'category', 'brand']\n",
            "\n",
            "  ‚Æï Extracted 4 claim-like strings\n",
            "\n",
            "  ‚Æï Claim type hints (for manual review):\n",
            "claim_type_hint\n",
            "low_fat    3\n",
            "light      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  ‚Æï Products with ‚â•1 claim snippet: 2\n",
            "\n",
            "‚úì Saved candidate claim strings to: data/candidate_claims_task2.csv\n",
            "  ‚Üí Use this CSV as a STARTING POINT for manual Task 2 annotation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Cell 7: Load claim-rich OFF subset from HuggingFace\n",
        "# ======================================================================\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "print(\"\\n‚û§ Loading OpenFoodFacts claim-rich subset...\\n\")\n",
        "\n",
        "# Target claim tags from OFF\n",
        "TARGET_TAGS = [\n",
        "    \"en:no-gluten\",\n",
        "    \"en:gluten-free\",\n",
        "    \"en:vegan\",\n",
        "    \"en:vegetarian\",\n",
        "    \"en:organic\",\n",
        "    \"en:no-lactose\",\n",
        "    \"en:lactose-free\",\n",
        "    \"en:no-palm-oil\",\n",
        "    \"en:palm-oil-free\",\n",
        "    \"en:low-fat\",\n",
        "    \"en:low-sugar\",\n",
        "    \"en:no-added-sugar\",\n",
        "    \"en:high-protein\",\n",
        "    \"en:high-fiber\",\n",
        "]\n",
        "\n",
        "# Map OFF tags to our claim types\n",
        "CLAIM_LABEL_MAP = {\n",
        "    \"en:no-gluten\": \"gluten_free\",\n",
        "    \"en:gluten-free\": \"gluten_free\",\n",
        "    \"en:vegan\": \"vegan\",\n",
        "    \"en:vegetarian\": \"vegetarian\",\n",
        "    \"en:organic\": \"organic\",\n",
        "    \"en:no-lactose\": \"lactose_free\",\n",
        "    \"en:lactose-free\": \"lactose_free\",\n",
        "    \"en:no-palm-oil\": \"palm_oil_free\",\n",
        "    \"en:palm-oil-free\": \"palm_oil_free\",\n",
        "    \"en:low-fat\": \"low_fat\",\n",
        "    \"en:low-sugar\": \"low_sugar\",\n",
        "    \"en:no-added-sugar\": \"no_added_sugar\",\n",
        "    \"en:high-protein\": \"high_protein\",\n",
        "    \"en:high-fiber\": \"high_fiber\",\n",
        "}\n",
        "\n",
        "print(f\"Mapped labels: {len(CLAIM_LABEL_MAP)} unique tags\\n\")\n",
        "\n",
        "def extract_main_text(val):\n",
        "    \"\"\"Extract main text from multilingual dict or return string.\"\"\"\n",
        "    if isinstance(val, dict):\n",
        "        return val.get(\"en\", \"\") or val.get(\"en-us\", \"\") or \"\"\n",
        "    return str(val) if val else \"\"\n",
        "\n",
        "def extract_ingredients_text(val):\n",
        "    \"\"\"Extract ingredient text from multilingual dict.\"\"\"\n",
        "    if isinstance(val, dict):\n",
        "        return val.get(\"en\", \"\") or val.get(\"en-us\", \"\") or \"\"\n",
        "    return str(val) if val else \"\"\n",
        "\n",
        "def get_float(d, key):\n",
        "    \"\"\"Extract float from nutriments dict, return None if invalid.\"\"\"\n",
        "    if not isinstance(d, dict):\n",
        "        return None\n",
        "    val = d.get(key)\n",
        "    if val is None:\n",
        "        return None\n",
        "    try:\n",
        "        f = float(val)\n",
        "        return f if not (math.isnan(f) or math.isinf(f)) else None\n",
        "    except (ValueError, TypeError):\n",
        "        return None\n",
        "\n",
        "def extract_nutriments(nutriments):\n",
        "    \"\"\"Extract key nutrients as floats (or None).\"\"\"\n",
        "    if not isinstance(nutriments, dict):\n",
        "        return {\n",
        "            \"energy_100g\": None,\n",
        "            \"fat_100g\": None,\n",
        "            \"saturated_fat_100g\": None,\n",
        "            \"carbs_100g\": None,\n",
        "            \"fiber_100g\": None,\n",
        "            \"sugars_100g\": None,\n",
        "            \"protein_100g\": None,\n",
        "            \"sodium_100g\": None,\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"energy_100g\": get_float(nutriments, \"energy-kcal_100g\"),\n",
        "        \"fat_100g\": get_float(nutriments, \"fat_100g\"),\n",
        "        \"saturated_fat_100g\": get_float(nutriments, \"saturated-fat_100g\"),\n",
        "        \"carbs_100g\": get_float(nutriments, \"carbohydrates_100g\"),\n",
        "        \"fiber_100g\": get_float(nutriments, \"fiber_100g\"),\n",
        "        \"sugars_100g\": get_float(nutriments, \"sugars_100g\"),\n",
        "        \"protein_100g\": get_float(nutriments, \"proteins_100g\"),\n",
        "        \"sodium_100g\": get_float(nutriments, \"sodium_100g\"),\n",
        "    }\n",
        "\n",
        "MAX_ROWS = 2000\n",
        "\n",
        "print(\"Loading OpenFoodFacts dataset (streaming from HuggingFace)...\")\n",
        "ds = load_dataset(\"openfoodfacts/product-database\", split=\"food\", streaming=True)\n",
        "\n",
        "rows = []\n",
        "seen_codes = set()\n",
        "n_scanned = 0\n",
        "\n",
        "for example in ds:\n",
        "    n_scanned += 1\n",
        "    labels_tags = example.get(\"labels_tags\") or []\n",
        "    labels_tags = [t for t in labels_tags if isinstance(t, str)]\n",
        "    matching_tags = [t for t in labels_tags if t in TARGET_TAGS]\n",
        "    if not matching_tags:\n",
        "        continue\n",
        "\n",
        "    code = example.get(\"code\")\n",
        "    if not code or code in seen_codes:\n",
        "        continue\n",
        "    seen_codes.add(code)\n",
        "\n",
        "    claim_types = []\n",
        "    for t in matching_tags:\n",
        "        mapped = CLAIM_LABEL_MAP.get(t)\n",
        "        if mapped:\n",
        "            claim_types.append(mapped)\n",
        "    if not claim_types:\n",
        "        continue\n",
        "\n",
        "    product_name = extract_main_text(example.get(\"product_name\"))\n",
        "    brand = (example.get(\"brands\") or \"\").strip()\n",
        "    categories = (example.get(\"categories\") or \"\").strip()\n",
        "    ingredients_text = extract_ingredients_text(example.get(\"ingredients_text\"))\n",
        "    labels_str = (example.get(\"labels\") or \"\").strip()\n",
        "    nutriments = extract_nutriments(example.get(\"nutriments\"))\n",
        "\n",
        "    row = {\n",
        "        \"product_id\": code,\n",
        "        \"name\": product_name,\n",
        "        \"brand\": brand,\n",
        "        \"category\": categories,\n",
        "        \"ingredients_text\": ingredients_text,\n",
        "        \"labels\": labels_str,\n",
        "        \"labels_tags\": \"|\".join(labels_tags),\n",
        "        \"claim_type_hint\": \";\".join(sorted(set(claim_types))),\n",
        "        \"source_field\": \"labels/labels_tags\",\n",
        "        \"full_text\": \" | \".join(\n",
        "            [x for x in [product_name, brand, categories, ingredients_text, labels_str] if x]\n",
        "        ),\n",
        "        **nutriments,\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "    if len(rows) % 200 == 0:\n",
        "        print(f\"  ‚Æï Collected {len(rows)} claim-rich products (scanned {n_scanned})...\")\n",
        "\n",
        "    if len(rows) >= MAX_ROWS:\n",
        "        break\n",
        "\n",
        "print(f\"\\n‚úì Finished. Collected {len(rows)} claim-rich products (scanned {n_scanned} total rows).\")\n",
        "\n",
        "df_claims = pd.DataFrame(rows)\n",
        "hf_output_path = DATA_DIR / \"openfoodfacts_claims_subset.csv\"\n",
        "df_claims.to_csv(hf_output_path, index=False)\n",
        "print(f\"‚úì Saved claim-rich subset to: {hf_output_path}\")\n",
        "\n",
        "# Show summary\n",
        "print(f\"\\nüìä OFF Claim Subset Summary:\")\n",
        "print(f\"  ‚Ä¢ Total products: {len(df_claims)}\")\n",
        "print(f\"  ‚Ä¢ With nutrition data: {df_claims[['fat_100g', 'protein_100g', 'sodium_100g', 'carbs_100g']].notna().any(axis=1).sum()}\")\n",
        "print(f\"  ‚Ä¢ With ingredients: {df_claims['ingredients_text'].notna().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKHWo1lLqJok",
        "outputId": "f629966e-5ffa-4877-8fcd-398e88801996"
      },
      "id": "rKHWo1lLqJok",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚û§ Loading OpenFoodFacts claim-rich subset...\n",
            "\n",
            "Mapped labels: 14 unique tags\n",
            "\n",
            "Loading OpenFoodFacts dataset (streaming from HuggingFace)...\n",
            "  ‚Æï Collected 200 claim-rich products (scanned 3090)...\n",
            "  ‚Æï Collected 400 claim-rich products (scanned 6062)...\n",
            "  ‚Æï Collected 600 claim-rich products (scanned 10910)...\n",
            "  ‚Æï Collected 800 claim-rich products (scanned 12581)...\n",
            "  ‚Æï Collected 1000 claim-rich products (scanned 14069)...\n",
            "  ‚Æï Collected 1200 claim-rich products (scanned 16534)...\n",
            "  ‚Æï Collected 1400 claim-rich products (scanned 20310)...\n",
            "  ‚Æï Collected 1600 claim-rich products (scanned 21411)...\n",
            "  ‚Æï Collected 1800 claim-rich products (scanned 23181)...\n",
            "  ‚Æï Collected 2000 claim-rich products (scanned 25987)...\n",
            "\n",
            "‚úì Finished. Collected 2000 claim-rich products (scanned 25987 total rows).\n",
            "‚úì Saved claim-rich subset to: data/openfoodfacts_claims_subset.csv\n",
            "\n",
            "üìä OFF Claim Subset Summary:\n",
            "  ‚Ä¢ Total products: 2000\n",
            "  ‚Ä¢ With nutrition data: 0\n",
            "  ‚Ä¢ With ingredients: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Cell 8: Filter noisy OFF rows (RELAXED - no nutrient requirement)\n",
        "# ======================================================================\n",
        "\n",
        "print(\"\\n‚û§ Filtering OFF products for quality...\\n\")\n",
        "\n",
        "# Try to load if not in memory\n",
        "try:\n",
        "    df_claims\n",
        "except NameError:\n",
        "    df_claims = pd.read_csv(DATA_DIR / \"openfoodfacts_claims_subset.csv\")\n",
        "    print(f\"Loaded {len(df_claims)} rows from saved CSV\")\n",
        "\n",
        "nutr_cols = [\n",
        "    \"energy_100g\", \"fat_100g\", \"saturated_fat_100g\",\n",
        "    \"carbs_100g\", \"fiber_100g\", \"sugars_100g\",\n",
        "    \"protein_100g\", \"sodium_100g\",\n",
        "]\n",
        "\n",
        "# 1) Basic non-empty checks\n",
        "mask_text = df_claims[\"full_text\"].fillna(\"\").str.len() > 10\n",
        "mask_claim = df_claims[\"claim_type_hint\"].fillna(\"\").str.strip().ne(\"\")\n",
        "\n",
        "df_tmp = df_claims[mask_text & mask_claim].copy()\n",
        "print(f\"  ‚Æï After text + claim filter: {len(df_tmp)}\")\n",
        "\n",
        "# 2) Nutrient filter ‚Äì DISABLED for OFF claim pool\n",
        "# We accept products even if all nutrients are missing, because\n",
        "# for Task 2 we mainly care about claim text.\n",
        "print(\"  ‚Æï Skipping nutrient-based filtering (nutriments often missing in OFF subset)\")\n",
        "\n",
        "# 3) Remove obviously bad categories\n",
        "bad_keywords = [\n",
        "    \"pet food\", \"dog\", \"cat\", \"beauty\", \"cosmetics\",\n",
        "    \"shampoo\", \"soap\", \"supplements\", \"dietary supplement\",\n",
        "]\n",
        "\n",
        "if len(df_tmp) > 0:\n",
        "    cat = df_tmp[\"category\"].fillna(\"\").str.lower()\n",
        "    mask_bad_cat = cat.apply(lambda x: any(k in x for k in bad_keywords))\n",
        "    df_tmp = df_tmp[~mask_bad_cat].copy()\n",
        "    print(f\"  ‚Æï After category filter: {len(df_tmp)}\")\n",
        "\n",
        "# 4) Deduplicate by product_id\n",
        "df_filtered = df_tmp.drop_duplicates(subset=\"product_id\").reset_index(drop=True)\n",
        "\n",
        "print(f\"\\n‚úì Final filtered OFF pool: {len(df_filtered)} products\")\n",
        "\n",
        "if len(df_filtered) > 0:\n",
        "    # These will likely be 0 because nutriments are often missing, but we log anyway\n",
        "    with_nutr = df_filtered[nutr_cols].notna().any(axis=1).sum()\n",
        "    print(f\"  ‚Ä¢ With ANY nutrition data: {with_nutr}\")\n",
        "    print(f\"  ‚Ä¢ With ingredients: {df_filtered['ingredients_text'].notna().sum()}\")\n",
        "\n",
        "    off_filtered_path = DATA_DIR / \"openfoodfacts_claims_filtered.csv\"\n",
        "    df_filtered.to_csv(off_filtered_path, index=False)\n",
        "    print(f\"\\n‚úì Saved filtered pool to: {off_filtered_path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No products passed filtering. Consider relaxing criteria further.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iu82qHcuonW",
        "outputId": "34a9847a-f871-4f60-b7a0-6de85cff1a71"
      },
      "id": "8iu82qHcuonW",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚û§ Filtering OFF products for quality...\n",
            "\n",
            "  ‚Æï After text + claim filter: 2000\n",
            "  ‚Æï Skipping nutrient-based filtering (nutriments often missing in OFF subset)\n",
            "  ‚Æï After category filter: 1996\n",
            "\n",
            "‚úì Final filtered OFF pool: 1996 products\n",
            "  ‚Ä¢ With ANY nutrition data: 0\n",
            "  ‚Ä¢ With ingredients: 1996\n",
            "\n",
            "‚úì Saved filtered pool to: data/openfoodfacts_claims_filtered.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Cell 9: Sample OFF products for manual annotation (FIXED)\n",
        "# ======================================================================\n",
        "\n",
        "print(\"\\n‚û§ Creating stratified OFF sample for manual annotation...\\n\")\n",
        "\n",
        "if len(df_filtered) == 0:\n",
        "    print(\"‚ö†Ô∏è  No products available for sampling.\")\n",
        "    print(\"   Skipping OFF sampling step.\")\n",
        "    sampled = pd.DataFrame()\n",
        "else:\n",
        "    # Create primary_claim from claim_type_hint\n",
        "    df_filtered[\"primary_claim\"] = (\n",
        "        df_filtered[\"claim_type_hint\"]\n",
        "        .fillna(\"\")\n",
        "        .str.split(\";\")\n",
        "        .str[0]\n",
        "        .str.strip()\n",
        "    )\n",
        "\n",
        "    # Remove rows where primary_claim is empty\n",
        "    df_filtered = df_filtered[df_filtered[\"primary_claim\"].ne(\"\")].copy()\n",
        "\n",
        "    print(f\"  ‚Æï Unique primary claims: {df_filtered['primary_claim'].nunique()}\")\n",
        "\n",
        "    # Target number of OFF products\n",
        "    TARGET_OFF = 120\n",
        "\n",
        "    per_label_target = max(1, TARGET_OFF // max(1, df_filtered[\"primary_claim\"].nunique()))\n",
        "\n",
        "    def _sample_group(g):\n",
        "        n = min(len(g), per_label_target)\n",
        "        return g.sample(n=n, random_state=RANDOM_SEED)\n",
        "\n",
        "    sampled = (\n",
        "        df_filtered\n",
        "        .groupby(\"primary_claim\", group_keys=False)\n",
        "        .apply(_sample_group)\n",
        "    )\n",
        "\n",
        "    # Top up if under target\n",
        "    if len(sampled) < TARGET_OFF:\n",
        "        remaining = df_filtered.drop(sampled.index)\n",
        "        extra_needed = TARGET_OFF - len(sampled)\n",
        "        if extra_needed > 0 and len(remaining) > 0:\n",
        "            extra = remaining.sample(\n",
        "                n=min(extra_needed, len(remaining)),\n",
        "                random_state=RANDOM_SEED,\n",
        "            )\n",
        "            sampled = pd.concat([sampled, extra], ignore_index=True)\n",
        "\n",
        "    sampled = sampled.reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\n‚úì Final OFF sample size: {len(sampled)}\")\n",
        "    print(\"\\n  Claim distribution:\")\n",
        "    print(sampled[\"primary_claim\"].value_counts())\n",
        "\n",
        "    # Save sampled subset\n",
        "    off_sampled_path = DATA_DIR / \"openfoodfacts_off_sample_for_manual.csv\"\n",
        "    sampled.to_csv(off_sampled_path, index=False)\n",
        "    print(f\"\\n‚úì Saved OFF sample to: {off_sampled_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K63jsQhIqLTl",
        "outputId": "49e9ebc5-8cb4-46c8-eb20-4c4bb1ad2d47"
      },
      "id": "K63jsQhIqLTl",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚û§ Creating stratified OFF sample for manual annotation...\n",
            "\n",
            "  ‚Æï Unique primary claims: 9\n",
            "\n",
            "‚úì Final OFF sample size: 120\n",
            "\n",
            "  Claim distribution:\n",
            "primary_claim\n",
            "gluten_free       24\n",
            "organic           24\n",
            "vegan             14\n",
            "vegetarian        14\n",
            "lactose_free      13\n",
            "low_fat           13\n",
            "no_added_sugar    13\n",
            "low_sugar          3\n",
            "palm_oil_free      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "‚úì Saved OFF sample to: data/openfoodfacts_off_sample_for_manual.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-492357703.py:38: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(_sample_group)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# NEW Cell: Build OFF claim table (per-claim rows) for manual Task 2\n",
        "# ======================================================================\n",
        "\n",
        "import re\n",
        "\n",
        "print(\"\\n‚û§ Building OFF claim table for manual Task 2 annotation...\\n\")\n",
        "\n",
        "if 'sampled' not in globals():\n",
        "    try:\n",
        "        sampled = pd.read_csv(DATA_DIR / \"openfoodfacts_off_sample_for_manual.csv\")\n",
        "        print(f\"Loaded OFF sample from CSV with {len(sampled)} rows\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ö†Ô∏è OFF sample not found. Run Cell 9 first.\")\n",
        "        sampled = pd.DataFrame()\n",
        "\n",
        "if sampled.empty:\n",
        "    print(\"‚ö†Ô∏è OFF sample is empty. Skipping claim-table creation.\")\n",
        "else:\n",
        "    off_df = sampled.copy()\n",
        "    print(f\"  ‚Æï Using OFF sample with {len(off_df)} products\")\n",
        "\n",
        "    def split_labels(labels_str):\n",
        "        if not isinstance(labels_str, str):\n",
        "            return []\n",
        "        parts = re.split(r\"[;,|]\", labels_str)\n",
        "        return [p.strip() for p in parts if p and p.strip()]\n",
        "\n",
        "    KEYWORDS = [\n",
        "        \"free\", \"no \", \"without\", \"low\", \"reduced\", \"rich\",\n",
        "        \"source\", \"high\", \"light\", \"0%\", \"0 %\", \"sans\", \"faible\", \"pauv\",\n",
        "    ]\n",
        "\n",
        "    def looks_like_claim(text):\n",
        "        if not text:\n",
        "            return False\n",
        "        t = text.lower()\n",
        "        if len(t) < 4:\n",
        "            return False\n",
        "        return any(k in t for k in KEYWORDS)\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for _, row in off_df.iterrows():\n",
        "        pid = row.get(\"product_id\", None)\n",
        "        name = row.get(\"name\", \"\")\n",
        "        brand = row.get(\"brand\", \"\")\n",
        "        full_text = row.get(\"full_text\", \"\")\n",
        "\n",
        "        labels = row.get(\"labels\", \"\")\n",
        "        label_candidates = split_labels(labels)\n",
        "\n",
        "        text = full_text if isinstance(full_text, str) else \"\"\n",
        "        extra_candidates = []\n",
        "        for chunk in re.split(r\"[.!?/]\", text):\n",
        "            chunk = chunk.strip()\n",
        "            if looks_like_claim(chunk):\n",
        "                extra_candidates.append(chunk)\n",
        "\n",
        "        all_candidates = set(\n",
        "            c for c in (label_candidates + extra_candidates) if looks_like_claim(c)\n",
        "        )\n",
        "\n",
        "        if not all_candidates:\n",
        "            # still create row so you can mark \"no claim\"\n",
        "            rows.append({\n",
        "                \"product_id\": pid,\n",
        "                \"name\": name,\n",
        "                \"brand\": brand,\n",
        "                \"source\": \"openfoodfacts_off_sample\",\n",
        "                \"raw_claim_text\": \"\",\n",
        "                \"full_text\": full_text,\n",
        "            })\n",
        "        else:\n",
        "            for claim_text in all_candidates:\n",
        "                rows.append({\n",
        "                    \"product_id\": pid,\n",
        "                    \"name\": name,\n",
        "                    \"brand\": brand,\n",
        "                    \"source\": \"openfoodfacts_off_sample\",\n",
        "                    \"raw_claim_text\": claim_text,\n",
        "                    \"full_text\": full_text,\n",
        "                })\n",
        "\n",
        "    off_claims_df = pd.DataFrame(rows).drop_duplicates(\n",
        "        subset=[\"product_id\", \"raw_claim_text\", \"source\"]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    print(f\"  ‚Æï Built {len(off_claims_df)} OFF claim rows\")\n",
        "    print(f\"  ‚Æï Products covered: {off_claims_df['product_id'].nunique()}\")\n",
        "\n",
        "    claims_out_path = DATA_DIR / \"claims_off_for_manual_task2.csv\"\n",
        "    off_claims_df.to_csv(claims_out_path, index=False)\n",
        "\n",
        "    print(f\"\\n‚úì Saved OFF claim table for manual annotation to: {claims_out_path}\")\n",
        "    display(off_claims_df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "NzfkPlz6uwXa",
        "outputId": "0dd67f0d-cdfe-4f5e-e977-af846d10ce01"
      },
      "id": "NzfkPlz6uwXa",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚û§ Building OFF claim table for manual Task 2 annotation...\n",
            "\n",
            "  ‚Æï Using OFF sample with 120 products\n",
            "  ‚Æï Built 305 OFF claim rows\n",
            "  ‚Æï Products covered: 120\n",
            "\n",
            "‚úì Saved OFF claim table for manual annotation to: data/claims_off_for_manual_task2.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      product_id                                               name  \\\n",
              "0  0027331000431  [{'lang': 'main', 'text': 'Corn Tortillas'}, {...   \n",
              "1  0016000457232  [{'lang': 'main', 'text': 'PEANUT BUTTER DARK ...   \n",
              "2  0016000457232  [{'lang': 'main', 'text': 'PEANUT BUTTER DARK ...   \n",
              "3  0028000255664  [{'lang': 'main', 'text': \"Taster's Choice 100...   \n",
              "4  0028000255664  [{'lang': 'main', 'text': \"Taster's Choice 100...   \n",
              "5  0025317007214  [{'lang': 'main', 'text': 'Uncured Beef Corn D...   \n",
              "6  0025317007214  [{'lang': 'main', 'text': 'Uncured Beef Corn D...   \n",
              "7  0025317007214  [{'lang': 'main', 'text': 'Uncured Beef Corn D...   \n",
              "8  0025317007214  [{'lang': 'main', 'text': 'Uncured Beef Corn D...   \n",
              "9  0025317007214  [{'lang': 'main', 'text': 'Uncured Beef Corn D...   \n",
              "\n",
              "                     brand                    source  \\\n",
              "0  Ole Mexican Foods  Inc.  openfoodfacts_off_sample   \n",
              "1            Nature Valley  openfoodfacts_off_sample   \n",
              "2            Nature Valley  openfoodfacts_off_sample   \n",
              "3                  Nescaf√©  openfoodfacts_off_sample   \n",
              "4                  Nescaf√©  openfoodfacts_off_sample   \n",
              "5       Applegate Naturals  openfoodfacts_off_sample   \n",
              "6       Applegate Naturals  openfoodfacts_off_sample   \n",
              "7       Applegate Naturals  openfoodfacts_off_sample   \n",
              "8       Applegate Naturals  openfoodfacts_off_sample   \n",
              "9       Applegate Naturals  openfoodfacts_off_sample   \n",
              "\n",
              "                                      raw_claim_text  \\\n",
              "0                                                      \n",
              "1  '}] | Sin gluten,Sin aromas artificiales,Sin c...   \n",
              "2                     en:No high fructose corn syrup   \n",
              "3  [{'lang': 'main', 'text': \"Taster's Choice 100...   \n",
              "4                                        Sans gluten   \n",
              "5                                          No gluten   \n",
              "6  GLUTEN-FREE BATTER: YELLOW CORN FLOUR, SUGAR, ...   \n",
              "7                                    '}] | No gluten   \n",
              "8  GLUTEN-FREE BATTER: YELLOW CORN FLOUR, SUGAR, ...   \n",
              "9  CONTAINS LESS THAN 2% OF THE FOLLOWING: SEA SA...   \n",
              "\n",
              "                                           full_text  \n",
              "0  [{'lang': 'main', 'text': 'Corn Tortillas'}, {...  \n",
              "1  [{'lang': 'main', 'text': 'PEANUT BUTTER DARK ...  \n",
              "2  [{'lang': 'main', 'text': 'PEANUT BUTTER DARK ...  \n",
              "3  [{'lang': 'main', 'text': \"Taster's Choice 100...  \n",
              "4  [{'lang': 'main', 'text': \"Taster's Choice 100...  \n",
              "5  [{'lang': 'main', 'text': 'Uncured Beef Corn D...  \n",
              "6  [{'lang': 'main', 'text': 'Uncured Beef Corn D...  \n",
              "7  [{'lang': 'main', 'text': 'Uncured Beef Corn D...  \n",
              "8  [{'lang': 'main', 'text': 'Uncured Beef Corn D...  \n",
              "9  [{'lang': 'main', 'text': 'Uncured Beef Corn D...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df7dd955-1eb1-4e39-9006-2e0c5ca584b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>name</th>\n",
              "      <th>brand</th>\n",
              "      <th>source</th>\n",
              "      <th>raw_claim_text</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0027331000431</td>\n",
              "      <td>[{'lang': 'main', 'text': 'Corn Tortillas'}, {...</td>\n",
              "      <td>Ole Mexican Foods  Inc.</td>\n",
              "      <td>openfoodfacts_off_sample</td>\n",
              "      <td></td>\n",
              "      <td>[{'lang': 'main', 'text': 'Corn Tortillas'}, {...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0016000457232</td>\n",
              "      <td>[{'lang': 'main', 'text': 'PEANUT BUTTER DARK ...</td>\n",
              "      <td>Nature Valley</td>\n",
              "      <td>openfoodfacts_off_sample</td>\n",
              "      <td>'}] | Sin gluten,Sin aromas artificiales,Sin c...</td>\n",
              "      <td>[{'lang': 'main', 'text': 'PEANUT BUTTER DARK ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0016000457232</td>\n",
              "      <td>[{'lang': 'main', 'text': 'PEANUT BUTTER DARK ...</td>\n",
              "      <td>Nature Valley</td>\n",
              "      <td>openfoodfacts_off_sample</td>\n",
              "      <td>en:No high fructose corn syrup</td>\n",
              "      <td>[{'lang': 'main', 'text': 'PEANUT BUTTER DARK ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0028000255664</td>\n",
              "      <td>[{'lang': 'main', 'text': \"Taster's Choice 100...</td>\n",
              "      <td>Nescaf√©</td>\n",
              "      <td>openfoodfacts_off_sample</td>\n",
              "      <td>[{'lang': 'main', 'text': \"Taster's Choice 100...</td>\n",
              "      <td>[{'lang': 'main', 'text': \"Taster's Choice 100...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0028000255664</td>\n",
              "      <td>[{'lang': 'main', 'text': \"Taster's Choice 100...</td>\n",
              "      <td>Nescaf√©</td>\n",
              "      <td>openfoodfacts_off_sample</td>\n",
              "      <td>Sans gluten</td>\n",
              "      <td>[{'lang': 'main', 'text': \"Taster's Choice 100...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0025317007214</td>\n",
              "      <td>[{'lang': 'main', 'text': 'Uncured Beef Corn D...</td>\n",
              "      <td>Applegate Naturals</td>\n",
              "      <td>openfoodfacts_off_sample</td>\n",
              "      <td>No gluten</td>\n",
              "      <td>[{'lang': 'main', 'text': 'Uncured Beef Corn D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0025317007214</td>\n",
              "      <td>[{'lang': 'main', 'text': 'Uncured Beef Corn D...</td>\n",
              "      <td>Applegate Naturals</td>\n",
              "      <td>openfoodfacts_off_sample</td>\n",
              "      <td>GLUTEN-FREE BATTER: YELLOW CORN FLOUR, SUGAR, ...</td>\n",
              "      <td>[{'lang': 'main', 'text': 'Uncured Beef Corn D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0025317007214</td>\n",
              "      <td>[{'lang': 'main', 'text': 'Uncured Beef Corn D...</td>\n",
              "      <td>Applegate Naturals</td>\n",
              "      <td>openfoodfacts_off_sample</td>\n",
              "      <td>'}] | No gluten</td>\n",
              "      <td>[{'lang': 'main', 'text': 'Uncured Beef Corn D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0025317007214</td>\n",
              "      <td>[{'lang': 'main', 'text': 'Uncured Beef Corn D...</td>\n",
              "      <td>Applegate Naturals</td>\n",
              "      <td>openfoodfacts_off_sample</td>\n",
              "      <td>GLUTEN-FREE BATTER: YELLOW CORN FLOUR, SUGAR, ...</td>\n",
              "      <td>[{'lang': 'main', 'text': 'Uncured Beef Corn D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0025317007214</td>\n",
              "      <td>[{'lang': 'main', 'text': 'Uncured Beef Corn D...</td>\n",
              "      <td>Applegate Naturals</td>\n",
              "      <td>openfoodfacts_off_sample</td>\n",
              "      <td>CONTAINS LESS THAN 2% OF THE FOLLOWING: SEA SA...</td>\n",
              "      <td>[{'lang': 'main', 'text': 'Uncured Beef Corn D...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df7dd955-1eb1-4e39-9006-2e0c5ca584b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df7dd955-1eb1-4e39-9006-2e0c5ca584b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df7dd955-1eb1-4e39-9006-2e0c5ca584b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9257e36b-ec6e-4d75-b5e3-563f95f0c0e4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9257e36b-ec6e-4d75-b5e3-563f95f0c0e4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9257e36b-ec6e-4d75-b5e3-563f95f0c0e4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(off_claims_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"product_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"0016000457232\",\n          \"0025317007214\",\n          \"0027331000431\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"[{'lang': 'main', 'text': 'PEANUT BUTTER DARK CHOCOLATE CHEWY BARS'}, {'lang': 'es', 'text': 'Protein peanut butter dark chocolate'}, {'lang': 'fr', 'text': 'Protein peanut butter dark chocolate chewy bars'}, {'lang': 'en', 'text': 'PEANUT BUTTER DARK CHOCOLATE CHEWY BARS'}]\",\n          \"[{'lang': 'main', 'text': 'Uncured Beef Corn Dogs'}, {'lang': 'en', 'text': 'Uncured Beef Corn Dogs'}]\",\n          \"[{'lang': 'main', 'text': 'Corn Tortillas'}, {'lang': 'es', 'text': 'Tortillas De Ma\\u00edz Amarillo'}, {'lang': 'en', 'text': 'Corn Tortillas'}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Nature Valley\",\n          \"Applegate Naturals\",\n          \"Ole Mexican Foods  Inc.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"openfoodfacts_off_sample\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_claim_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"GLUTEN-FREE BATTER: YELLOW CORN FLOUR, SUGAR, YELLOW CORN MEAL, TAPIOCA STARCH, RICE FLOUR, <span class=\\\"allergen\\\">EGG WHITES<\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"[{'lang': 'main', 'text': 'PEANUT BUTTER DARK CHOCOLATE CHEWY BARS'}, {'lang': 'es', 'text': 'Protein peanut butter dark chocolate'}, {'lang': 'fr', 'text': 'Protein peanut butter dark chocolate chewy bars'}, {'lang': 'en', 'text': 'PEANUT BUTTER DARK CHOCOLATE CHEWY BARS'}] | Nature Valley | Botanas,Snacks dulces,Barritas,Suplementos diet\\u00e9ticos,Suplementos de culturismo,Barritas de prote\\u00ednas | [{'lang': 'main', 'text': 'Roasted Peanuts, Soy Protein Isolate, Chicory Root Extract, Semisweet Chocolate Chips (sugar, chocolate liquor, cocoa butter, soy lecithin, natural flavor), Vegetable Oils (palm, palm kernel, canola, peanut), Sugar, Corn Syrup, Whey Protein Concentrate, Fructose, Peanut Butter (peanuts, salt), Cocoa, Vegetable Glycerin, Rice Starch, Soy Lecithin, Salt, Corn Starch, Natural Flavor.'}, {'lang': 'fr', 'text': 'Cacahuates tostados 25,7%, aislado de prote\\u00edna de soya, extracto de ra\\u00edz de achicoria, chispas de chocolate semiamargo 7,4% (azucar, licor de cacao, manteca de cacao, lecitina de soya, saborizante natural), aceite vegetal (aceite de semilla de palma, aceite de palma, aceite de canola, aceite de cacahuate), az\\u00facar, jarabe de ma\\u00edz, s\\u00f3lidos de la leche, fructosa, crema de cacahuate (cacahuates, sal), cacao en polvo, glicerina, almid\\u00f3n, lecitina de soya, sal, almid\\u00f3n, saborizante natural. CONTIENE CACAHUATE, SOYA E INGREDIENTES DE LECHE.'}, {'lang': 'en', 'text': 'Roasted Peanuts, <span class=\\\"allergen\\\">Soy Protein Isolate</span>, Chicory Root Extract, Semisweet Chocolate Chips (sugar, chocolate liquor, cocoa butter, <span class=\\\"allergen\\\">soy lecithin</span>, natural flavor), Vegetable Oils (palm, palm kernel, canola, <span class=\\\"allergen\\\">peanut</span>), Sugar, Corn Syrup, Whey Protein Concentrate, Fructose, Peanut Butter (<span class=\\\"allergen\\\">peanuts</span>, salt), Cocoa, Vegetable Glycerin, Rice Starch, <span class=\\\"allergen\\\">Soy Lecithin</span>, Salt, Corn Starch, Natural Flavor.'}, {'lang': 'fr', 'text': 'Cacahuates tostados 25,7%, aislado de prote\\u00edna de soya, extracto de ra\\u00edz de achicoria, chispas de chocolate semiamargo 7,4% (azucar, licor de cacao, manteca de cacao, lecitina de soya, saborizante natural), aceite vegetal (aceite de semilla de palma, aceite de palma, aceite de canola, aceite de cacahuate), az\\u00facar, jarabe de ma\\u00edz, s\\u00f3lidos de la leche, fructosa, crema de cacahuate (cacahuates, sal), cacao en polvo, glicerina, almid\\u00f3n, lecitina de soya, sal, almid\\u00f3n, saborizante natural. CONTIENE CACAHUATE, SOYA E INGREDIENTES DE LECHE.'}, {'lang': 'en', 'text': 'Roasted Peanuts, Soy Protein Isolate, Chicory Root Extract, Semisweet Chocolate Chips (sugar, chocolate liquor, cocoa butter, soy lecithin, natural flavor), Vegetable Oils (palm, palm kernel, canola, peanut), Sugar, Corn Syrup, Whey Protein Concentrate, Fructose, Peanut Butter (peanuts, salt), Cocoa, Vegetable Glycerin, Rice Starch, Soy Lecithin, Salt, Corn Starch, Natural Flavor.'}] | Sin gluten,Sin aromas artificiales,Sin colorantes artificiales,en:No high fructose corn syrup\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# Cell 10: Final summary and reproducibility check\n",
        "# ======================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"NOTEBOOK 00 COMPLETION SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n‚úÖ COMPLETED TASKS:\")\n",
        "print(\"  1. Loaded base products.csv\")\n",
        "print(\"  2. Computed per-serving nutrition and Task 1 labels\")\n",
        "print(\"  3. Created stratified train/val/test splits\")\n",
        "print(\"  4. Generated candidate claims for manual Task 2 annotation\")\n",
        "print(\"  5. Loaded and filtered OpenFoodFacts claim-rich subset\")\n",
        "print(\"  6. Created stratified OFF sample for manual annotation\")\n",
        "\n",
        "print(\"\\nüìÅ OUTPUT FILES:\")\n",
        "files_created = [\n",
        "    \"train.csv\",\n",
        "    \"val.csv\",\n",
        "    \"test.csv\",\n",
        "    \"candidate_claims_task2.csv\",\n",
        "    \"openfoodfacts_claims_subset.csv\",\n",
        "    \"openfoodfacts_claims_filtered.csv\",\n",
        "    \"openfoodfacts_off_sample_for_manual.csv\"\n",
        "]\n",
        "\n",
        "for fname in files_created:\n",
        "    path = DATA_DIR / fname\n",
        "    if path.exists():\n",
        "        size = path.stat().st_size / 1024\n",
        "        print(f\"  ‚úì {fname} ({size:.1f} KB)\")\n",
        "    else:\n",
        "        print(f\"  ‚ö†Ô∏è  {fname} (NOT FOUND)\")\n",
        "\n",
        "print(\"\\nüìä CURRENT DATA STATUS:\")\n",
        "print(f\"  ‚Ä¢ Products in train/val/test: {len(df)}\")\n",
        "print(f\"  ‚Ä¢ Task 1 labels: ‚úì Complete\")\n",
        "print(f\"  ‚Ä¢ Task 2 claim candidates: {len(candidates_df)} snippets\")\n",
        "print(f\"  ‚Ä¢ Task 3 ready: ‚úì Ingredients available\")\n",
        "\n",
        "print(\"\\n‚è≠Ô∏è  NEXT STEPS FOR GRADE CONTRACT:\")\n",
        "print(\"\\n  FOR B GRADE (minimum 120 products):\")\n",
        "print(\"    ‚Ä¢ Current products: {len(df)}\")\n",
        "if len(df) >= 120:\n",
        "    print(\"    ‚úì You have enough products!\")\n",
        "else:\n",
        "    print(f\"    ‚ö†Ô∏è  Need {120 - len(df)} more products\")\n",
        "print(\"    ‚Ä¢ Manually annotate Task 1 on all products\")\n",
        "print(\"    ‚Ä¢ Manually annotate Task 2 on ‚â•50 claims\")\n",
        "print(\"    ‚Ä¢ Implement rule-based + TF-IDF baselines\")\n",
        "\n",
        "print(\"\\n  FOR B+ GRADE (minimum 180 products):\")\n",
        "if len(df) >= 180:\n",
        "    print(\"    ‚úì You have enough products!\")\n",
        "else:\n",
        "    print(f\"    ‚ö†Ô∏è  Need {180 - len(df)} more products\")\n",
        "print(\"    ‚Ä¢ Expand Task 2 to ‚â•120 claims with explanations\")\n",
        "print(\"    ‚Ä¢ Double-annotate ‚â•25 products (Cohen's kappa)\")\n",
        "print(\"    ‚Ä¢ Implement BERT baseline\")\n",
        "\n",
        "print(\"\\n  FOR A- GRADE (minimum 200 products):\")\n",
        "if len(df) >= 200:\n",
        "    print(\"    ‚úì You have enough products!\")\n",
        "else:\n",
        "    print(f\"    ‚ö†Ô∏è  Need {200 - len(df)} more products\")\n",
        "print(\"    ‚Ä¢ Expand Task 2 to ‚â•160 claims\")\n",
        "print(\"    ‚Ä¢ Start Task 3 BIO tagging on ‚â•80 products\")\n",
        "print(\"    ‚Ä¢ Implement multimodal model\")\n",
        "\n",
        "print(\"\\n  FOR A GRADE (minimum 200 products):\")\n",
        "if len(df) >= 200:\n",
        "    print(\"    ‚úì You have enough products!\")\n",
        "else:\n",
        "    print(f\"    ‚ö†Ô∏è  Need {200 - len(df)} more products\")\n",
        "print(\"    ‚Ä¢ Complete Task 3 on ‚â•120 products\")\n",
        "print(\"    ‚Ä¢ Implement claim-table model\")\n",
        "print(\"    ‚Ä¢ Perform slice-based analysis\")\n",
        "\n",
        "print(\"\\nüîí REPRODUCIBILITY:\")\n",
        "print(f\"  ‚Ä¢ Random seed: {RANDOM_SEED}\")\n",
        "print(\"  ‚Ä¢ All splits saved with stratification\")\n",
        "print(\"  ‚Ä¢ All intermediate files saved\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  IMPORTANT REMINDERS:\")\n",
        "print(\"  ‚Ä¢ candidate_claims_task2.csv is ONLY a helper\")\n",
        "print(\"  ‚Ä¢ ALL Task 2 labels must be manually annotated\")\n",
        "print(\"  ‚Ä¢ Task 3 BIO tagging must be manual\")\n",
        "print(\"  ‚Ä¢ Follow FDA thresholds for Task 1 verification\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Notebook 00 complete! Ready for manual annotation.\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMpVaXtVqUdA",
        "outputId": "98b8cfcd-5997-4901-ea7c-09f462802845"
      },
      "id": "bMpVaXtVqUdA",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "NOTEBOOK 00 COMPLETION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "‚úÖ COMPLETED TASKS:\n",
            "  1. Loaded base products.csv\n",
            "  2. Computed per-serving nutrition and Task 1 labels\n",
            "  3. Created stratified train/val/test splits\n",
            "  4. Generated candidate claims for manual Task 2 annotation\n",
            "  5. Loaded and filtered OpenFoodFacts claim-rich subset\n",
            "  6. Created stratified OFF sample for manual annotation\n",
            "\n",
            "üìÅ OUTPUT FILES:\n",
            "  ‚úì train.csv (79.8 KB)\n",
            "  ‚úì val.csv (19.0 KB)\n",
            "  ‚úì test.csv (17.9 KB)\n",
            "  ‚úì candidate_claims_task2.csv (0.5 KB)\n",
            "  ‚úì openfoodfacts_claims_subset.csv (3491.5 KB)\n",
            "  ‚úì openfoodfacts_claims_filtered.csv (3478.7 KB)\n",
            "  ‚úì openfoodfacts_off_sample_for_manual.csv (244.0 KB)\n",
            "\n",
            "üìä CURRENT DATA STATUS:\n",
            "  ‚Ä¢ Products in train/val/test: 279\n",
            "  ‚Ä¢ Task 1 labels: ‚úì Complete\n",
            "  ‚Ä¢ Task 2 claim candidates: 4 snippets\n",
            "  ‚Ä¢ Task 3 ready: ‚úì Ingredients available\n",
            "\n",
            "‚è≠Ô∏è  NEXT STEPS FOR GRADE CONTRACT:\n",
            "\n",
            "  FOR B GRADE (minimum 120 products):\n",
            "    ‚Ä¢ Current products: {len(df)}\n",
            "    ‚úì You have enough products!\n",
            "    ‚Ä¢ Manually annotate Task 1 on all products\n",
            "    ‚Ä¢ Manually annotate Task 2 on ‚â•50 claims\n",
            "    ‚Ä¢ Implement rule-based + TF-IDF baselines\n",
            "\n",
            "  FOR B+ GRADE (minimum 180 products):\n",
            "    ‚úì You have enough products!\n",
            "    ‚Ä¢ Expand Task 2 to ‚â•120 claims with explanations\n",
            "    ‚Ä¢ Double-annotate ‚â•25 products (Cohen's kappa)\n",
            "    ‚Ä¢ Implement BERT baseline\n",
            "\n",
            "  FOR A- GRADE (minimum 200 products):\n",
            "    ‚úì You have enough products!\n",
            "    ‚Ä¢ Expand Task 2 to ‚â•160 claims\n",
            "    ‚Ä¢ Start Task 3 BIO tagging on ‚â•80 products\n",
            "    ‚Ä¢ Implement multimodal model\n",
            "\n",
            "  FOR A GRADE (minimum 200 products):\n",
            "    ‚úì You have enough products!\n",
            "    ‚Ä¢ Complete Task 3 on ‚â•120 products\n",
            "    ‚Ä¢ Implement claim-table model\n",
            "    ‚Ä¢ Perform slice-based analysis\n",
            "\n",
            "üîí REPRODUCIBILITY:\n",
            "  ‚Ä¢ Random seed: 42\n",
            "  ‚Ä¢ All splits saved with stratification\n",
            "  ‚Ä¢ All intermediate files saved\n",
            "\n",
            "‚ö†Ô∏è  IMPORTANT REMINDERS:\n",
            "  ‚Ä¢ candidate_claims_task2.csv is ONLY a helper\n",
            "  ‚Ä¢ ALL Task 2 labels must be manually annotated\n",
            "  ‚Ä¢ Task 3 BIO tagging must be manual\n",
            "  ‚Ä¢ Follow FDA thresholds for Task 1 verification\n",
            "\n",
            "======================================================================\n",
            "Notebook 00 complete! Ready for manual annotation.\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}